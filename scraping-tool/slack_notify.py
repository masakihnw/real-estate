#!/usr/bin/env python3
"""
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã®å·®åˆ†ã‚’å–å¾—ã—ã€Slackã«é€šçŸ¥ã™ã‚‹ã€‚
å‰å›çµæœï¼ˆlatest.jsonï¼‰ã¨ç¾åœ¨çµæœã‚’æ¯”è¼ƒã—ã¦ã€æ–°è¦ãƒ»ä¾¡æ ¼å¤‰å‹•ãƒ»å‰Šé™¤ã‚’æ¤œå‡ºã€‚
"""

import json
import os
import sys
from pathlib import Path
from typing import Any, Optional

from optional_features import optional_features
from report_utils import (
    compare_listings,
    format_area,
    format_floor,
    format_ownership,
    format_price,
    format_total_units,
    get_station_group,
    get_ward_from_address,
    google_maps_url,
    load_json,
    row_merge_key,
    TOKYO_23_WARDS,
)


def format_diff_message(
    diff: dict[str, Any],
    current_count: int,
    report_url: Optional[str] = None,
    map_url: Optional[str] = None,
) -> str:
    """å·®åˆ†ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«æ•´å½¢ã€‚report_url / map_url ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãã®ãƒªãƒ³ã‚¯ã‚’ä½¿ã†ã€‚"""
    new_count = len(diff["new"])
    updated_count = len(diff["updated"])
    removed_count = len(diff["removed"])

    lines = [
        "ğŸ  *ä¸­å¤ãƒãƒ³ã‚·ãƒ§ãƒ³ç‰©ä»¶æƒ…å ± æ›´æ–°é€šçŸ¥*",
        "",
        f"ğŸ“Š *ç¾åœ¨ã®ä»¶æ•°*: {current_count}ä»¶",
        "",
    ]

    if new_count > 0 or updated_count > 0 or removed_count > 0:
        lines.append("*ğŸ“ˆ å¤‰æ›´ã‚µãƒãƒªãƒ¼*")
        if new_count > 0:
            lines.append(f"  ğŸ†• æ–°è¦: {new_count}ä»¶")
        if updated_count > 0:
            lines.append(f"  ğŸ”„ ä¾¡æ ¼å¤‰å‹•: {updated_count}ä»¶")
        if removed_count > 0:
            lines.append(f"  âŒ å‰Šé™¤: {removed_count}ä»¶")
        lines.append("")

    # æ–°è¦ç‰©ä»¶ï¼ˆæœ€å¤§5ä»¶ï¼‰
    if diff["new"]:
        lines.append("*ğŸ†• æ–°è¦ç‰©ä»¶*")
        for r in sorted(diff["new"], key=lambda x: x.get("price_man") or 0)[:5]:
            name = r.get("name", "")[:40]
            price = format_price(r.get("price_man"))
            layout = r.get("layout", "-")
            area_str = format_area(r.get("area_m2"))
            lines.append(f"  â€¢ {name}")
            lines.append(f"    {price} | {layout} | {area_str}")
        if len(diff["new"]) > 5:
            lines.append(f"  ... ä»– {len(diff['new']) - 5}ä»¶")
        lines.append("")

    # ä¾¡æ ¼å¤‰å‹•ï¼ˆæœ€å¤§5ä»¶ã€å·®é¡ãŒå¤§ãã„é †ï¼‰
    if diff["updated"]:
        lines.append("*ğŸ”„ ä¾¡æ ¼å¤‰å‹•*")
        sorted_updated = sorted(
            diff["updated"],
            key=lambda x: abs((x["current"].get("price_man") or 0) - (x["previous"].get("price_man") or 0)),
            reverse=True,
        )
        for item in sorted_updated[:5]:
            curr = item["current"]
            prev = item["previous"]
            name = curr.get("name", "")[:40]
            prev_price = format_price(prev.get("price_man"))
            curr_price = format_price(curr.get("price_man"))
            diff_price = (curr.get("price_man") or 0) - (prev.get("price_man") or 0)
            diff_str = f"{'+' if diff_price >= 0 else ''}{diff_price}ä¸‡å††"
            lines.append(f"  â€¢ {name}")
            lines.append(f"    {prev_price} â†’ {curr_price} ({diff_str})")
        if len(diff["updated"]) > 5:
            lines.append(f"  ... ä»– {len(diff['updated']) - 5}ä»¶")
        lines.append("")

    # å‰Šé™¤ã•ã‚ŒãŸç‰©ä»¶ï¼ˆæœ€å¤§5ä»¶ï¼‰
    if diff["removed"]:
        lines.append("*âŒ å‰Šé™¤ã•ã‚ŒãŸç‰©ä»¶*")
        for r in diff["removed"][:5]:
            name = r.get("name", "")[:40]
            price = format_price(r.get("price_man"))
            lines.append(f"  â€¢ {name} ({price})")
        if len(diff["removed"]) > 5:
            lines.append(f"  ... ä»– {len(diff['removed']) - 5}ä»¶")
        lines.append("")

    if new_count == 0 and updated_count == 0 and removed_count == 0:
        lines.append("å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    lines.append("")
    if report_url:
        lines.append(f"ğŸ“„ è©³ç´°: <{report_url}|ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèª>")
    else:
        lines.append("ğŸ“„ è©³ç´°: <https://github.com/masakihnw/dev-workspace/blob/main/personal/projects/real-estate/scraping-tool/results/report/report.md|ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèª>")
    if map_url:
        lines.append(f"ğŸ“Œ åœ°å›³: <{map_url}|åœ°å›³ã§è¦‹ã‚‹ï¼ˆã‚¹ãƒãƒ›å¯ï¼‰>")

    return "\n".join(lines)


# 1æŠ•ç¨¿ã‚ãŸã‚Šã®æ–‡å­—æ•°ä¸Šé™ï¼ˆSlackæ¨å¥¨ã¯40000æœªæº€ã€‚ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼‰
SLACK_CHUNK_SIZE = 35000
# 1ãƒãƒ£ãƒ³ã‚¯é€ä¿¡ã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
SLACK_SEND_RETRIES = 5
# ãƒªãƒˆãƒ©ã‚¤é–“éš”ï¼ˆç§’ï¼‰
SLACK_RETRY_DELAY_SEC = 2


def send_slack_message(webhook_url: str, message: str) -> bool:
    """Slack Incoming Webhookã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’1é€šé€ä¿¡ã€‚"""
    import urllib.request
    import urllib.parse

    payload = {"text": message}
    data = json.dumps(payload).encode("utf-8")

    try:
        req = urllib.request.Request(
            webhook_url,
            data=data,
            headers={"Content-Type": "application/json"},
        )
        with urllib.request.urlopen(req, timeout=10) as response:
            return response.status == 200
    except Exception as e:
        print(f"Slacké€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        return False


def send_slack_message_chunked_with_retry(webhook_url: str, message: str) -> bool:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡ã—åˆ‡ã‚‹ã¾ã§ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ã€‚"""
    import time

    if not message.strip():
        return True
    chunks: list[str] = []
    rest = message
    while rest:
        if len(rest) <= SLACK_CHUNK_SIZE:
            chunks.append(rest)
            break
        # è¡Œå¢ƒç•Œã§åˆ†å‰²ï¼ˆé•·ã„è¡Œã®é€”ä¸­ã§åˆ‡ã‚‰ãªã„ï¼‰
        cut = rest[:SLACK_CHUNK_SIZE]
        last_nl = cut.rfind("\n")
        if last_nl > SLACK_CHUNK_SIZE // 2:
            chunks.append(rest[: last_nl + 1])
            rest = rest[last_nl + 1 :]
        else:
            chunks.append(cut)
            rest = rest[SLACK_CHUNK_SIZE:]
    for i, chunk in enumerate(chunks):
        for attempt in range(SLACK_SEND_RETRIES):
            if send_slack_message(webhook_url, chunk):
                if len(chunks) > 1:
                    print(f"Slack: ãƒãƒ£ãƒ³ã‚¯ {i + 1}/{len(chunks)} é€ä¿¡å®Œäº†", file=sys.stderr)
                break
            if attempt < SLACK_SEND_RETRIES - 1:
                time.sleep(SLACK_RETRY_DELAY_SEC)
                print(f"Slack: ãƒãƒ£ãƒ³ã‚¯ {i + 1} ãƒªãƒˆãƒ©ã‚¤ ({attempt + 2}/{SLACK_SEND_RETRIES})", file=sys.stderr)
        else:
            print(f"Slack: ãƒãƒ£ãƒ³ã‚¯ {i + 1}/{len(chunks)} ãŒé€ä¿¡ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒªãƒˆãƒ©ã‚¤ä¸Šé™ï¼‰", file=sys.stderr)
            return False
    return True


def report_url_from_current_path(current_path: Path) -> Optional[str]:
    """current_YYYYMMDD_HHMMSS.json ã®ãƒ‘ã‚¹ã‹ã‚‰ã€ãã®å®Ÿè¡Œã®ãƒ¬ãƒãƒ¼ãƒˆ GitHub URL ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚"""
    stem = current_path.stem  # e.g. current_20260128_074236
    if not stem.startswith("current_"):
        return None
    timestamp = stem[8:]  # 20260128_074236
    report_filename = f"report_{timestamp}.md"
    base = "https://github.com/masakihnw/dev-workspace/blob/main/personal/projects/real-estate/scraping-tool/results"
    return f"{base}/{report_filename}"


def report_url_from_report_path(report_path: Path) -> Optional[str]:
    """report_YYYYMMDD_HHMMSS.md ã®ãƒ‘ã‚¹ã‹ã‚‰ GitHub URL ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚"""
    if not report_path or not report_path.name.startswith("report_") or not report_path.name.endswith(".md"):
        return None
    base = "https://github.com/masakihnw/dev-workspace/blob/main/personal/projects/real-estate/scraping-tool/results"
    return f"{base}/{report_path.name}"


def map_url_from_report_url(report_url: Optional[str]) -> Optional[str]:
    """
    GitHub ã®ãƒ¬ãƒãƒ¼ãƒˆ URL ã‹ã‚‰ã€åŒä¸€ãƒªãƒã‚¸ãƒˆãƒªã® map_viewer.html ã‚’
    htmlpreview ã§é–‹ã URL ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚ã‚¹ãƒãƒ›ã‹ã‚‰ã‚‚é–²è¦§å¯èƒ½ã€‚
    """
    if not report_url or "github.com" not in report_url or "/blob/" not in report_url:
        return None
    # https://github.com/OWNER/REPO/blob/BRANCH/path å½¢å¼ â†’ raw URL
    raw = report_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
    if "report/report.md" in raw:
        raw = raw.replace("report/report.md", "map_viewer.html")
    elif "results/report.md" in raw or raw.endswith("/report.md"):
        raw = raw.replace("results/report.md", "results/map_viewer.html").replace("/report.md", "/map_viewer.html")
    else:
        raw = raw.rstrip("/").rsplit("/", 1)[0] + "/map_viewer.html" if "/" in raw else raw + "/map_viewer.html"
    return f"https://htmlpreview.github.io/?{raw}"


# Slack ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¸Šé™ï¼ˆä½™è£•ã‚’æŒã£ã¦ï¼‰
SLACK_TEXT_LIMIT = 35000


def _listing_line_slack(r: dict, url: str = "", include_breakdown: bool = True) -> str:
    """1ç‰©ä»¶ã‚’Slackç”¨1è¡Œã«ã€‚æˆ¸æ•°ãƒ»éšæ•°ãƒ»æ¨©åˆ©ãƒ»è³‡ç”£æ€§ãƒ»10å¹´å¾Œ(ä¸­ç«‹)ãƒ»é€šå‹¤æ™‚é–“ï¼ˆM3ãƒ»PGï¼‰ã‚’å¿…ãšå«ã‚€ã€‚"""
    _, rank, breakdown = optional_features.get_asset_score_and_rank_with_breakdown(r)
    _, neu_10y, _ = optional_features.get_three_scenario_columns(r)
    m3_str, pg_str = optional_features.get_commute_display_with_estimate(r.get("station_line"), r.get("walk_min"))
    name = (r.get("name") or "")[:28]
    price = format_price(r.get("price_man"))
    layout = r.get("layout", "-")
    area = format_area(r.get("area_m2"))
    built = f"ç¯‰{r.get('built_year', '-')}å¹´" if r.get("built_year") else "-"
    walk = optional_features.format_all_station_walk(r.get("station_line"), r.get("walk_min"))
    # æˆ¸æ•°ãƒ»éšæ•°ãƒ»æ¨©åˆ©ã¯å¿…ãšè¡¨ç¤ºï¼ˆå–å¾—ã§ããªã„å ´åˆã¯ã€Œæˆ¸æ•°:ä¸æ˜ã€ã€Œéš:-ã€ã€Œæ¨©åˆ©:ä¸æ˜ã€ï¼‰
    floor_str = format_floor(r.get("floor_position"), r.get("floor_total"), r.get("floor_structure"))
    units = format_total_units(r.get("total_units"))
    ownership_str = format_ownership(r.get("ownership"))
    parts = [name, price, layout, area, built, walk, floor_str, units, ownership_str, rank]
    if include_breakdown:
        parts.append(breakdown)
    parts.append(f"10å¹´å¾Œ:{neu_10y}")
    monthly_loan, _ = optional_features.get_loan_display_for_listing(r.get("price_man"))
    parts.extend([f"æœˆé¡:{monthly_loan}"])
    parts.extend([f"M3:{m3_str}", f"PG:{pg_str}"])
    line = "â€¢ " + " ï½œ ".join(parts)
    map_url = google_maps_url(r.get("name") or r.get("address") or "")
    if map_url:
        line += f" ï½œ <{map_url}|Map>"
    if url:
        line += f" ï½œ <{url}|è©³ç´°>"
    return line


def build_slack_message_from_listings(
    current: list[dict[str, Any]],
    previous: Optional[list[dict[str, Any]]],
    report_url: Optional[str] = None,
    map_url: Optional[str] = None,
) -> str:
    """Slackç”¨ã«Markdownè¡¨ã‚’ä½¿ã‚ãšã€è¦‹ã‚„ã™ã„ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚è³‡ç”£æ€§Bä»¥ä¸Šã®ç‰©ä»¶ã®ã¿ã€‚"""
    from collections import defaultdict

    # è³‡ç”£æ€§Bä»¥ä¸Šã«çµã‚‹
    current_a = [r for r in current if optional_features.get_asset_score_and_rank(r)[1] in ("S", "A", "B")]
    diff = compare_listings(current, previous) if previous else {}
    diff_new_a = [r for r in diff.get("new", []) if optional_features.get_asset_score_and_rank(r)[1] in ("S", "A", "B")]
    diff_updated_a = [item for item in diff.get("updated", []) if optional_features.get_asset_score_and_rank(item.get("current", {}))[1] in ("S", "A", "B")]
    diff_removed_a = [r for r in diff.get("removed", []) if optional_features.get_asset_score_and_rank(r)[1] in ("S", "A", "B")]

    new_c = len(diff_new_a)
    upd_c = len(diff_updated_a)
    rem_c = len(diff_removed_a)

    lines = [
        "ğŸ  *ä¸­å¤ãƒãƒ³ã‚·ãƒ§ãƒ³ç‰©ä»¶æƒ…å ±*ï¼ˆè³‡ç”£æ€§Bä»¥ä¸Šã®ã¿ï¼‰",
        "",
        f"ğŸ“Š å¯¾è±¡ä»¶æ•°: {len(current_a)}ä»¶ï¼ˆBä»¥ä¸Š / å…¨{len(current)}ä»¶ä¸­ï¼‰",
        "",
    ]

    # â–  ä»Šå›ã®å¤‰æ›´ï¼ˆæ–°è¦è¿½åŠ ãƒ»å‰Šé™¤ãƒ»ä¾¡æ ¼å¤‰å‹•ã‚’å†’é ­ã§æ˜ç¤ºï¼‰
    if new_c or upd_c or rem_c:
        lines.append("*â–  ä»Šå›ã®å¤‰æ›´*")
        lines.append(f"  ğŸ†• *æ–°è¦è¿½åŠ *: {new_c}ä»¶")
        lines.append(f"  âŒ *å‰Šé™¤*: {rem_c}ä»¶")
        lines.append(f"  ğŸ”„ *ä¾¡æ ¼å¤‰å‹•*: {upd_c}ä»¶")
        lines.append("")

    # æ–°è¦è¿½åŠ ã•ã‚ŒãŸç‰©ä»¶ï¼ˆåŒºã«é–¢ä¿‚ãªãä¸€ç•ªä¸Šï¼‰
    if diff_new_a:
        lines.append("*ğŸ†• æ–°è¦è¿½åŠ ã•ã‚ŒãŸç‰©ä»¶*")
        for r in sorted(diff_new_a, key=lambda x: x.get("price_man") or 0)[:10]:
            url = r.get("url", "")
            lines.append(_listing_line_slack(r, url))
        if len(diff_new_a) > 10:
            lines.append(f"  â€¦ ä»– {len(diff_new_a) - 10}ä»¶")
        lines.append("")

    # ä¾¡æ ¼å¤‰å‹•ã—ãŸç‰©ä»¶ï¼ˆæœ€å¤§5ä»¶ï¼‰ã€‚æˆ¸æ•°ãƒ»éšæ•°ãƒ»æ¨©åˆ©ã‚’å¿…ãšå«ã‚ã‚‹
    if diff_updated_a:
        lines.append("*ğŸ”„ ä¾¡æ ¼å¤‰å‹•ã—ãŸç‰©ä»¶*")
        for item in sorted(
            diff_updated_a,
            key=lambda x: abs((x["current"].get("price_man") or 0) - (x["previous"].get("price_man") or 0)),
            reverse=True,
        )[:5]:
            c = item["current"]
            prev_p = format_price(item["previous"].get("price_man"))
            curr_p = format_price(c.get("price_man"))
            floor_str = format_floor(c.get("floor_position"), c.get("floor_total"), c.get("floor_structure"))
            units = format_total_units(c.get("total_units"))
            ownership_str = format_ownership(c.get("ownership"))
            map_url = google_maps_url(c.get("name") or c.get("address") or "")
            detail_part = f" ï½œ <{c.get('url', '')}|è©³ç´°>" if c.get("url") else ""
            map_part = f" ï½œ <{map_url}|Map>" if map_url else ""
            lines.append(f"â€¢ {(c.get('name') or '')[:28]} ï½œ {prev_p} â†’ {curr_p} ï½œ {floor_str} ï½œ {units} ï½œ {ownership_str}{map_part}{detail_part}")
        if len(diff_updated_a) > 5:
            lines.append(f"  â€¦ ä»– {len(diff_updated_a) - 5}ä»¶")
        lines.append("")

    # å‰Šé™¤ã•ã‚ŒãŸç‰©ä»¶ï¼ˆæœ€å¤§5ä»¶ï¼‰ã€‚æˆ¸æ•°ãƒ»éšæ•°ãƒ»æ¨©åˆ©ã‚’å¿…ãšå«ã‚ã‚‹
    if diff_removed_a:
        lines.append("*âŒ å‰Šé™¤ã•ã‚ŒãŸç‰©ä»¶*")
        for r in diff_removed_a[:5]:
            floor_str = format_floor(r.get("floor_position"), r.get("floor_total"), r.get("floor_structure"))
            units = format_total_units(r.get("total_units"))
            ownership_str = format_ownership(r.get("ownership"))
            map_url = google_maps_url(r.get("name") or r.get("address") or "")
            map_part = f" ï½œ <{map_url}|Map>" if map_url else ""
            lines.append(f"â€¢ {(r.get('name') or '')[:28]} ï½œ {format_price(r.get('price_man'))} ï½œ {floor_str} ï½œ {units} ï½œ {ownership_str}{map_part}")
        if len(diff_removed_a) > 5:
            lines.append(f"  â€¦ ä»– {len(diff_removed_a) - 5}ä»¶")
        lines.append("")

    # ç‰©ä»¶ä¸€è¦§ï¼ˆåŒºãƒ»é§…åˆ¥ã€è³‡ç”£æ€§Bä»¥ä¸Šã®ã¿ï¼‰
    ward_order = {w: i for i, w in enumerate(TOKYO_23_WARDS)}
    by_ward: dict[str, list[dict]] = defaultdict(list)
    for r in current_a:
        ward = get_ward_from_address(r.get("address") or "")
        if ward:
            by_ward[ward].append(r)
        else:
            by_ward["(åŒºä¸æ˜)"].append(r)
    ordered_wards = sorted(by_ward.keys(), key=lambda w: ward_order.get(w, 999))

    lines.append("*ğŸ“‹ ç‰©ä»¶ä¸€è¦§ï¼ˆåŒºãƒ»é§…åˆ¥ãƒ»è³‡ç”£æ€§Bä»¥ä¸Šï¼‰*")
    lines.append("  _ç‰©ä»¶å ï½œ ä¾¡æ ¼ ï½œ é–“å– ï½œ å°‚æœ‰ ï½œ ç¯‰ ï½œ å¾’æ­© ï½œ éš ï½œ æˆ¸æ•° ï½œ æ¨©åˆ© ï½œ ãƒ©ãƒ³ã‚¯ ï½œ â€¦ ï½œ 10å¹´å¾Œ(ä¸­ç«‹) ï½œ æœˆé¡ ï½œ M3 ï½œ PG ï½œ Map ï½œ è©³ç´°_")
    lines.append("")
    for ward in ordered_wards:
        ward_listings = by_ward.get(ward, [])
        if not ward_listings:
            continue
        lines.append(f"*{ward}*")
        by_station: dict[str, list[dict]] = defaultdict(list)
        for r in ward_listings:
            st = get_station_group(r.get("station_line") or "")
            by_station[st].append(r)
        for station in sorted(by_station.keys()):
            st_listings = by_station[station]
            merge_groups: dict[tuple, list[dict]] = defaultdict(list)
            for r in st_listings:
                merge_groups[row_merge_key(r)].append(r)
            for group in sorted(merge_groups.values(), key=lambda g: (g[0].get("price_man") or 0)):
                r = group[0]
                urls = [x.get("url", "") for x in group if x.get("url")]
                url = urls[0] if urls else ""
                lines.append(f"  _{station}_")
                lines.append(f"  {_listing_line_slack(r, url)}")
        lines.append("")

    if report_url:
        lines.append(f"ğŸ“„ <{report_url}|ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèª>")
    else:
        lines.append("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ: GitHub ã® results/report ã‚’ç¢ºèª")
    if map_url:
        lines.append(f"ğŸ“Œ <{map_url}|åœ°å›³ã§è¦‹ã‚‹ï¼ˆã‚¹ãƒãƒ›å¯ï¼‰>")

    return "\n".join(lines)


def build_message_from_report(report_path: Path, report_url: Optional[str] = None) -> Optional[str]:
    """ãƒ¬ãƒãƒ¼ãƒˆ md ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’èª­ã¿å–ã‚Šã€Slack æŠ•ç¨¿æ–‡ã«ã™ã‚‹ã€‚â€»Slackç”¨ã«ã¯ build_slack_message_from_listings ã‚’æ¨å¥¨ã€‚"""
    if not report_path or not report_path.exists():
        return None
    try:
        content = report_path.read_text(encoding="utf-8").strip()
    except Exception:
        return None
    if len(content) > SLACK_TEXT_LIMIT:
        content = content[:SLACK_TEXT_LIMIT] + "\n\n... (æ–‡å­—æ•°åˆ¶é™ã®ãŸã‚çœç•¥ã€‚è©³ç´°ã¯ä¸‹è¨˜ãƒªãƒ³ã‚¯ã‹ã‚‰)"
    if report_url:
        content += f"\n\nğŸ“„ è©³ç´°: <{report_url}|ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèª>"
    return content


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã€‚"""
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: python slack_notify.py <current.json> [previous.json] [report.md]", file=sys.stderr)
        sys.exit(1)

    current_path = Path(sys.argv[1])
    previous_path = Path(sys.argv[2]) if len(sys.argv) > 2 else current_path.parent / "latest.json"
    report_path = Path(sys.argv[3]) if len(sys.argv) > 3 and sys.argv[3] else None

    webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
    if not webhook_url:
        print("è­¦å‘Š: SLACK_WEBHOOK_URL ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆé€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰", file=sys.stderr)
        sys.exit(0)  # ã‚¨ãƒ©ãƒ¼ã§ã¯ãªãè­¦å‘Šã¨ã—ã¦æ‰±ã„ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ç¶šè¡Œ

    current = load_json(current_path, missing_ok=True, default=[])
    previous = load_json(previous_path, missing_ok=True, default=[]) if previous_path else []

    # æŠ•ç¨¿å¯¾è±¡ã¯è³‡ç”£æ€§Bä»¥ä¸Šã®ã¿ã€‚å‰å›ã‚ã‚Šã‹ã¤Bä»¥ä¸Šã«çµã£ãŸå·®åˆ†ãŒãªã‘ã‚Œã°æŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹
    if previous:
        diff = compare_listings(current, previous)
        diff_new_a = [r for r in diff.get("new", []) if optional_features.get_asset_score_and_rank(r)[1] in ("S", "A", "B")]
        diff_updated_a = [item for item in diff.get("updated", []) if optional_features.get_asset_score_and_rank(item.get("current", {}))[1] in ("S", "A", "B")]
        diff_removed_a = [r for r in diff.get("removed", []) if optional_features.get_asset_score_and_rank(r)[1] in ("S", "A", "B")]
        if not diff_new_a and not diff_updated_a and not diff_removed_a:
            print("å¤‰æ›´ãªã—ï¼ˆè³‡ç”£æ€§Bä»¥ä¸Šã®æ–°è¦ãƒ»å‰Šé™¤ãƒ»ä¾¡æ ¼å¤‰å‹•ãªã—ï¼‰Slacké€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™", file=sys.stderr)
            sys.exit(0)

    report_url = report_url_from_report_path(report_path) if report_path else report_url_from_current_path(current_path)
    map_url = map_url_from_report_url(report_url)
    # Slackç”¨ã¯Markdownè¡¨ã‚’ä½¿ã‚ãªã„è¦‹ã‚„ã™ã„å½¢å¼ã§æŠ•ç¨¿ã€‚é•·æ–‡ã¯ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã—ã€é€ã‚Šåˆ‡ã‚Œã‚‹ã¾ã§ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ã€‚
    message = build_slack_message_from_listings(current, previous, report_url, map_url=map_url)

    if send_slack_message_chunked_with_retry(webhook_url, message):
        print("Slacké€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸ", file=sys.stderr)
    else:
        print("Slacké€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒªãƒˆãƒ©ã‚¤å¾Œã‚‚é€ä¿¡ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
