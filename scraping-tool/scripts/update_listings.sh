#!/bin/bash
# å®šæœŸå®Ÿè¡Œç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: ç‰©ä»¶æƒ…å ±ã‚’å–å¾—ã—ã€Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
#
# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹æˆ:
#   Phase 1:  ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆä¸­å¤ & æ–°ç¯‰ã‚’ä¸¦åˆ—å®Ÿè¡Œï¼‰
#   Phase 2a: å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›¸ãè¾¼ã¿ enricherï¼ˆé †æ¬¡å®Ÿè¡Œã§ç«¶åˆå›žé¿ï¼‰
#   Phase 2b: èª­ã¿å–ã‚Šå°‚ç”¨ enricherï¼ˆä¸­å¤/æ–°ç¯‰/æˆç´„å®Ÿç¸¾ã®3ãƒˆãƒ©ãƒƒã‚¯ä¸¦åˆ—ï¼‰
#   Phase 2c: å…±æœ‰ãƒžãƒ‹ãƒ•ã‚§ã‚¹ãƒˆæ›¸ãè¾¼ã¿ï¼ˆupload_floor_plans ã‚’é †æ¬¡å®Ÿè¡Œï¼‰
#   Phase 3:  åˆæµ â†’ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ â†’ é€šçŸ¥ â†’ ã‚³ãƒŸãƒƒãƒˆ

set -e

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆé…ç½®ãŒ scraping-tool/scripts/ ã§ã‚ã‚‹å‰æã€‚ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ scraping-tool/
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$SCRIPT_DIR"

OUTPUT_DIR="results"
REPORT_DIR="${OUTPUT_DIR}/report"
mkdir -p "$REPORT_DIR"

DATE=$(TZ=Asia/Tokyo date +%Y%m%d_%H%M%S)
CURRENT="${OUTPUT_DIR}/current_${DATE}.json"
REPORT="${REPORT_DIR}/report.md"

CURRENT_SHINCHIKU="${OUTPUT_DIR}/current_shinchiku_${DATE}.json"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ‰€è¦æ™‚é–“è¨ˆæ¸¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TIMING_DIR="${OUTPUT_DIR}/.timing"
mkdir -p "$TIMING_DIR"
rm -f "$TIMING_DIR"/*.tsv
PIPELINE_START=$(date +%s)

record_timing() {
    local timing_file="$1"
    local step_name="$2"
    local start_time="$3"
    local end_time=$(date +%s)
    local elapsed=$((end_time - start_time))
    local minutes=$((elapsed / 60))
    local seconds=$((elapsed % 60))
    echo "[TIMING] ${step_name}: ${minutes}m ${seconds}s" >&2
    printf "%s\t%d\n" "$step_name" "$elapsed" >> "$timing_file"
}

print_timing_summary() {
    local pipeline_end=$(date +%s)
    local pipeline_elapsed=$((pipeline_end - PIPELINE_START))
    local pipeline_min=$((pipeline_elapsed / 60))
    local pipeline_sec=$((pipeline_elapsed % 60))

    echo "" >&2
    echo "==========================================" >&2
    echo " æ‰€è¦æ™‚é–“ã‚µãƒžãƒªãƒ¼" >&2
    echo "==========================================" >&2
    printf "%-40s %10s\n" "ã‚¹ãƒ†ãƒƒãƒ—" "æ‰€è¦æ™‚é–“" >&2
    echo "---------------------------------------------------" >&2

    for tsv_file in "$TIMING_DIR"/main.tsv "$TIMING_DIR"/phase2a.tsv "$TIMING_DIR"/track_a.tsv "$TIMING_DIR"/track_b.tsv "$TIMING_DIR"/track_c.tsv "$TIMING_DIR"/phase2c.tsv; do
        [ -f "$tsv_file" ] || continue
        local label=""
        case "$tsv_file" in
            *track_a*) label="  [Track A: ä¸­å¤]" ;;
            *track_b*) label="  [Track B: æ–°ç¯‰]" ;;
            *track_c*) label="  [Track C: æˆç´„å®Ÿç¸¾]" ;;
        esac
        [ -n "$label" ] && echo "$label" >&2
        local indent="  "
        [ -n "$label" ] && indent="    "
        while IFS=$'\t' read -r step_name elapsed; do
            local minutes=$((elapsed / 60))
            local seconds=$((elapsed % 60))
            printf "${indent}%-36s %4dm %02ds\n" "$step_name" "$minutes" "$seconds" >&2
        done < "$tsv_file"
    done

    echo "---------------------------------------------------" >&2
    printf "  %-38s %4dm %02ds\n" "TOTAL" "$pipeline_min" "$pipeline_sec" >&2
    echo "==========================================" >&2

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚è¨˜éŒ²
    echo "" >> "$LOG_FILE"
    echo "=== æ‰€è¦æ™‚é–“ã‚µãƒžãƒªãƒ¼ ===" >> "$LOG_FILE"
    for tsv_file in "$TIMING_DIR"/main.tsv "$TIMING_DIR"/phase2a.tsv "$TIMING_DIR"/track_a.tsv "$TIMING_DIR"/track_b.tsv "$TIMING_DIR"/track_c.tsv "$TIMING_DIR"/phase2c.tsv; do
        [ -f "$tsv_file" ] || continue
        while IFS=$'\t' read -r step_name elapsed; do
            local minutes=$((elapsed / 60))
            local seconds=$((elapsed % 60))
            printf "[TIMING] %s: %dm %ds\n" "$step_name" "$minutes" "$seconds" >> "$LOG_FILE"
        done < "$tsv_file"
    done
    printf "[TIMING] TOTAL: %dm %ds\n" "$pipeline_min" "$pipeline_sec" >> "$LOG_FILE"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BG_PIDS=""
register_bg_pid() { BG_PIDS="$BG_PIDS $1"; }
kill_bg_pids() {
    for pid in $BG_PIDS; do
        kill "$pid" 2>/dev/null && echo "ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ—ãƒ­ã‚»ã‚¹ $pid ã‚’åœæ­¢" >&2 || true
    done
    BG_PIDS=""
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ­ã‚°è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_FILE="${OUTPUT_DIR}/scraping_log.txt"
exec 3>&2  # å…ƒã® stderr ã‚’ fd3 ã«é€€é¿
exec 2> >(tee -a "$LOG_FILE" >&3)  # stderr ã‚’ tee ã§ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«åˆ†å²

echo "=== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚° ===" > "$LOG_FILE"
echo "å®Ÿè¡Œæ—¥æ™‚: $(TZ=Asia/Tokyo date '+%Y-%m-%d %H:%M:%S')ï¼ˆJSTï¼‰" >> "$LOG_FILE"
echo "==========================================" >> "$LOG_FILE"

# ã‚¨ãƒ©ãƒ¼æ™‚: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢ â†’ ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚µãƒžãƒªãƒ¼ â†’ ãƒ­ã‚°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
trap '
    echo "=== ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šä¸­æ–­ ===" >&2
    kill_bg_pids
    print_timing_summary 2>/dev/null || true
    echo "=== ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šä¸­æ–­ ===" >> "$LOG_FILE"
    python3 upload_scraping_log.py "$LOG_FILE" --status error 2>/dev/null || true
' ERR

echo "=== ç‰©ä»¶æƒ…å ±å–å¾—é–‹å§‹ ===" >&2
echo "æ—¥æ™‚: $(TZ=Asia/Tokyo date '+%Y-%m-%d %H:%M:%S')ï¼ˆJSTï¼‰" >&2

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 1: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆä¸­å¤ãƒ»æ–°ç¯‰ã‚’ä¸¦åˆ—å®Ÿè¡Œï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo "--- Phase 1: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆä¸­å¤ãƒ»æ–°ç¯‰ä¸¦åˆ—å®Ÿè¡Œï¼‰ ---" >&2

_t_chuko=$(date +%s)
python3 main.py --source suumo --property-type chuko -o "$CURRENT" &
CHUKO_PID=$!
register_bg_pid $CHUKO_PID

_t_shinchiku=$(date +%s)
python3 main.py --source suumo --property-type shinchiku -o "$CURRENT_SHINCHIKU" &
SHINCHIKU_PID=$!
register_bg_pid $SHINCHIKU_PID

echo "[ä¸¦åˆ—] ä¸­å¤ (PID: $CHUKO_PID) + æ–°ç¯‰ (PID: $SHINCHIKU_PID) ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œä¸­..." >&2

# ä¸­å¤å®Œäº†ã‚’å¾…æ©Ÿï¼ˆå¿…é ˆ: set -e ã«ã‚ˆã‚Šå¤±æ•—æ™‚ã¯ ERR trap â†’ æ–°ç¯‰ã‚‚åœæ­¢ã—ã¦ exitï¼‰
wait $CHUKO_PID
record_timing "$TIMING_DIR/main.tsv" "scraping_chuko" "$_t_chuko"

# æ–°ç¯‰å®Œäº†ã‚’å¾…æ©Ÿï¼ˆå¤±æ•—ã¯è¨±å®¹ã—ã¦ç¶šè¡Œï¼‰
wait $SHINCHIKU_PID || echo "æ–°ç¯‰å–å¾—ã‚¨ãƒ©ãƒ¼ï¼ˆä¸­å¤ã¯ç¶šè¡Œï¼‰" >&2
record_timing "$TIMING_DIR/main.tsv" "scraping_shinchiku" "$_t_shinchiku"

BG_PIDS=""  # ä¸¡æ–¹å®Œäº†ã—ãŸã®ã§ã‚¯ãƒªã‚¢

# ä¸­å¤ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
if [ ! -s "$CURRENT" ]; then
    echo "ã‚¨ãƒ©ãƒ¼: ä¸­å¤ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ" >&2
    exit 1
fi

COUNT=$(python3 -c "import json; print(len(json.load(open('$CURRENT'))))")
if [ "$COUNT" -eq 0 ]; then
    echo "ã‚¨ãƒ©ãƒ¼: ä¸­å¤ãƒ‡ãƒ¼ã‚¿ãŒ 0 ä»¶ã§ã™ï¼ˆãƒ•ã‚£ãƒ«ã‚¿è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰" >&2
    exit 1
fi
echo "ä¸­å¤å–å¾—ä»¶æ•°: ${COUNT}ä»¶" >&2

SHINCHIKU_COUNT=0
if [ -s "$CURRENT_SHINCHIKU" ]; then
    SHINCHIKU_COUNT=$(python3 -c "import json; print(len(json.load(open('$CURRENT_SHINCHIKU'))))")
fi
echo "æ–°ç¯‰å–å¾—ä»¶æ•°: ${SHINCHIKU_COUNT}ä»¶" >&2

# â”€â”€â”€ å¤‰æ›´æ¤œå‡º â”€â”€â”€
_t=$(date +%s)
HAS_CHANGES=false
if [ -f "${OUTPUT_DIR}/latest.json" ]; then
    if python3 check_changes.py "$CURRENT" "${OUTPUT_DIR}/latest.json"; then
        echo "ä¸­å¤: å¤‰æ›´ã‚ã‚Š" >&2
        HAS_CHANGES=true
    else
        echo "ä¸­å¤: å¤‰æ›´ãªã—" >&2
    fi
else
    HAS_CHANGES=true  # åˆå›žå®Ÿè¡Œ
fi

if [ -s "$CURRENT_SHINCHIKU" ] && [ -f "${OUTPUT_DIR}/latest_shinchiku.json" ]; then
    if python3 check_changes.py "$CURRENT_SHINCHIKU" "${OUTPUT_DIR}/latest_shinchiku.json"; then
        echo "æ–°ç¯‰: å¤‰æ›´ã‚ã‚Š" >&2
        HAS_CHANGES=true
    else
        echo "æ–°ç¯‰: å¤‰æ›´ãªã—" >&2
    fi
elif [ -s "$CURRENT_SHINCHIKU" ]; then
    HAS_CHANGES=true  # æ–°ç¯‰åˆå›ž
fi
record_timing "$TIMING_DIR/main.tsv" "change_detection" "$_t"

if [ "$HAS_CHANGES" = false ]; then
    echo "ä¸­å¤ãƒ»æ–°ç¯‰ã¨ã‚‚ã«å¤‰æ›´ãªã—ï¼ˆãƒ¬ãƒãƒ¼ãƒˆãƒ»é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰" >&2
    rm -f "$CURRENT" "$CURRENT_SHINCHIKU"
    echo "ãƒ­ã‚°ã‚’ Firestore ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ï¼ˆå¤‰æ›´ãªã—ï¼‰..." >&2
    print_timing_summary
    python3 upload_scraping_log.py "$LOG_FILE" --status success 2>&1 || echo "ãƒ­ã‚°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—" >&2
    exit 0
fi

# GitHub Actions å®Ÿè¡Œæ™‚ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ»ãƒžãƒƒãƒ— URL
REPORT_URL_ARG=""
MAP_URL_ARG=""
if [ -n "${GITHUB_REPOSITORY:-}" ] && [ -n "${GITHUB_REF_NAME:-}" ]; then
    REPORT_URL="https://github.com/${GITHUB_REPOSITORY}/blob/${GITHUB_REF_NAME}/scraping-tool/results/report/report.md"
    REPORT_URL_ARG="--report-url ${REPORT_URL}"
    MAP_URL="https://htmlpreview.github.io/?https://raw.githubusercontent.com/${GITHUB_REPOSITORY}/${GITHUB_REF_NAME}/scraping-tool/results/map_viewer.html"
    MAP_URL_ARG="--map-url ${MAP_URL}"
fi

# â”€â”€â”€ latest.json / latest_shinchiku.json ä¿å­˜ â”€â”€â”€
cp "${OUTPUT_DIR}/latest.json" "${OUTPUT_DIR}/previous.json" 2>/dev/null || true
cp "$CURRENT" "${OUTPUT_DIR}/latest.json"
if [ -s "$CURRENT_SHINCHIKU" ]; then
    cp "${OUTPUT_DIR}/latest_shinchiku.json" "${OUTPUT_DIR}/previous_shinchiku.json" 2>/dev/null || true
    cp "$CURRENT_SHINCHIKU" "${OUTPUT_DIR}/latest_shinchiku.json"
    echo "æ–°ç¯‰: ${OUTPUT_DIR}/latest_shinchiku.json ã«ä¿å­˜" >&2
fi

# â”€â”€â”€ is_new ãƒ•ãƒ©ã‚°æ³¨å…¥ â”€â”€â”€
echo "is_new ãƒ•ãƒ©ã‚°ã‚’æ³¨å…¥ä¸­..." >&2
python3 -c "
import json, sys
sys.path.insert(0, '.')
from report_utils import inject_is_new, load_json
from pathlib import Path

out = '${OUTPUT_DIR}'

cur = load_json(Path(f'{out}/latest.json'))
prev = load_json(Path(f'{out}/previous.json'), missing_ok=True, default=[])
inject_is_new(cur, prev or None)
with open(f'{out}/latest.json', 'w', encoding='utf-8') as f:
    json.dump(cur, f, ensure_ascii=False)

cur_s = load_json(Path(f'{out}/latest_shinchiku.json'), missing_ok=True, default=[])
prev_s = load_json(Path(f'{out}/previous_shinchiku.json'), missing_ok=True, default=[])
if cur_s:
    inject_is_new(cur_s, prev_s or None)
    with open(f'{out}/latest_shinchiku.json', 'w', encoding='utf-8') as f:
        json.dump(cur_s, f, ensure_ascii=False)

new_c = sum(1 for r in cur if r.get('is_new'))
new_s = sum(1 for r in cur_s if r.get('is_new'))
print(f'is_new æ³¨å…¥å®Œäº†: ä¸­å¤ {new_c}/{len(cur)}ä»¶, æ–°ç¯‰ {new_s}/{len(cur_s)}ä»¶', file=sys.stderr)
" || echo "is_new æ³¨å…¥å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2

# â”€â”€â”€ ä¾¡æ ¼å¤‰å‹•ãƒ»æŽ²è¼‰æ—¥æ•°ãƒ»ç«¶åˆç‰©ä»¶æ•°æ³¨å…¥ â”€â”€â”€
echo "ä¾¡æ ¼å¤‰å‹•ãƒ»æŽ²è¼‰æ—¥æ•°ãƒ»ç«¶åˆç‰©ä»¶æ•°ã‚’æ³¨å…¥ä¸­..." >&2
python3 -c "
import json, sys
sys.path.insert(0, '.')
from report_utils import inject_price_history, inject_first_seen_at, inject_competing_count, load_json
from pathlib import Path

out = '${OUTPUT_DIR}'

cur = load_json(Path(f'{out}/latest.json'))
prev = load_json(Path(f'{out}/previous.json'), missing_ok=True, default=[])
inject_price_history(cur, prev or None)
inject_first_seen_at(cur, prev or None)
inject_competing_count(cur)
with open(f'{out}/latest.json', 'w', encoding='utf-8') as f:
    json.dump(cur, f, ensure_ascii=False)

cur_s = load_json(Path(f'{out}/latest_shinchiku.json'), missing_ok=True, default=[])
prev_s = load_json(Path(f'{out}/previous_shinchiku.json'), missing_ok=True, default=[])
if cur_s:
    inject_price_history(cur_s, prev_s or None)
    inject_first_seen_at(cur_s, prev_s or None)
    inject_competing_count(cur_s)
    with open(f'{out}/latest_shinchiku.json', 'w', encoding='utf-8') as f:
        json.dump(cur_s, f, ensure_ascii=False)

print(f'ä¾¡æ ¼å¤‰å‹•ãƒ»æŽ²è¼‰æ—¥æ•°ãƒ»ç«¶åˆç‰©ä»¶æ•° æ³¨å…¥å®Œäº†', file=sys.stderr)
" || echo "ä¾¡æ ¼å¤‰å‹•æ³¨å…¥å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2

# â”€â”€â”€ enrichment å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— â”€â”€â”€
cp "${OUTPUT_DIR}/latest.json" "${OUTPUT_DIR}/latest.json.backup"
[ -s "${OUTPUT_DIR}/latest_shinchiku.json" ] && cp "${OUTPUT_DIR}/latest_shinchiku.json" "${OUTPUT_DIR}/latest_shinchiku.json.backup" || true

# â”€â”€â”€ ãƒ–ãƒ©ã‚¦ã‚¶ãƒ•ãƒ©ã‚°æ¤œå‡º â”€â”€â”€
BROWSER_FLAG=""
if python3 -c "
import sys
try:
    from playwright.sync_api import sync_playwright
    with sync_playwright() as p:
        path = p.chromium.executable_path
        import os
        if os.path.isfile(path):
            sys.exit(0)
        else:
            sys.exit(1)
except Exception:
    sys.exit(1)
" 2>/dev/null; then
    BROWSER_FLAG="--browser"
    echo "playwright æ¤œå‡ºï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ãƒã‚¤ãƒŠãƒªç¢ºèªæ¸ˆã¿ï¼‰: ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•åŒ–ã‚’å«ã‚ã¦å®Ÿè¡Œ" >&2
else
    echo "playwright æœªæ¤œå‡ºã¾ãŸã¯ãƒ–ãƒ©ã‚¦ã‚¶ãƒã‚¤ãƒŠãƒªãªã—: ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•åŒ–ã‚¹ã‚­ãƒƒãƒ—" >&2
fi

# â”€â”€â”€ æ±äº¬éƒ½åœ°åŸŸå±é™ºåº¦ GeoJSON ç”Ÿæˆï¼ˆåˆå›žã®ã¿ã€Phase 2 å‰ã«å®Ÿè¡Œã—ã¦ç«¶åˆã‚’å›žé¿ï¼‰ â”€â”€â”€
RISK_GEOJSON_DIR="${OUTPUT_DIR}/risk_geojson"
if [ ! -f "${RISK_GEOJSON_DIR}/building_collapse_risk.geojson" ]; then
    echo "æ±äº¬éƒ½åœ°åŸŸå±é™ºåº¦ GeoJSON ã‚’ç”Ÿæˆä¸­ï¼ˆåˆå›žã®ã¿ï¼‰..." >&2
    _t=$(date +%s)
    python3 scripts/convert_risk_geojson.py 2>&1 || echo "GeoJSON å¤‰æ›å¤±æ•—ï¼ˆgeopandas æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼Ÿ GSI ã‚¿ã‚¤ãƒ«ã®ã¿ã§ãƒã‚¶ãƒ¼ãƒ‰åˆ¤å®šã‚’ç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_DIR/main.tsv" "risk_geojson" "$_t"
else
    echo "æ±äº¬éƒ½åœ°åŸŸå±é™ºåº¦ GeoJSON: ç”Ÿæˆæ¸ˆã¿ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰" >&2
fi

HAS_SHINCHIKU=false
[ -s "${OUTPUT_DIR}/latest_shinchiku.json" ] && HAS_SHINCHIKU=true

TIMING_2A="$TIMING_DIR/phase2a.tsv"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 2a: å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›¸ãè¾¼ã¿ enricherï¼ˆé †æ¬¡å®Ÿè¡Œã§ç«¶åˆå›žé¿ï¼‰
#   - sumai_surfin_cache.json, geocode_cache.json, station_cache.json ç­‰ã‚’
#     å®‰å…¨ã«èª­ã¿æ›¸ãã™ã‚‹ãŸã‚ã€ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã¯å…¨ã¦é †æ¬¡å®Ÿè¡Œã™ã‚‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo "" >&2
echo "--- Phase 2a: å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ enricherï¼ˆé †æ¬¡å®Ÿè¡Œï¼‰ ---" >&2
_t_phase2a=$(date +%s)

# 2a-1. build_units_cache (ä¸­å¤) ã¨ shinchiku_detail_enricher (æ–°ç¯‰) ã¯
#       åˆ¥ã€…ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆhtml_cache/ vs shinchiku_html_cache/ï¼‰ã‚’ä½¿ã†ãŸã‚ä¸¦åˆ—å¯èƒ½
_t=$(date +%s)
echo "build_units_cache (ä¸­å¤) + shinchiku_detail_enricher (æ–°ç¯‰) ä¸¦åˆ—å®Ÿè¡Œä¸­..." >&2

python3 scripts/build_units_cache.py "${OUTPUT_DIR}/latest.json" &
BU_PID=$!
register_bg_pid $BU_PID

SD_PID=""
if [ "$HAS_SHINCHIKU" = true ]; then
    python3 shinchiku_detail_enricher.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" &
    SD_PID=$!
    register_bg_pid $SD_PID
fi

wait $BU_PID || echo "build_units_cache ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆç¶šè¡Œï¼‰" >&2
record_timing "$TIMING_2A" "build_units_cache" "$_t"

if [ -n "$SD_PID" ]; then
    wait $SD_PID || echo "shinchiku_detail_enricher ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_2A" "shinchiku_detail_enricher" "$_t"
fi
BG_PIDS=""

# 2a-2. merge_detail_cache (ä¸­å¤: build_units_cache ã®çµæžœã‚’ãƒžãƒ¼ã‚¸)
_t=$(date +%s)
python3 scripts/merge_detail_cache.py "${OUTPUT_DIR}/latest.json" || echo "è©³ç´°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒžãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆç¶šè¡Œï¼‰" >&2
record_timing "$TIMING_2A" "merge_detail_cache" "$_t"

# 2a-3. ä½ã¾ã„ã‚µãƒ¼ãƒ•ã‚£ãƒ³ enrichmentï¼ˆå…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ sumai_surfin_cache.json ã®ãŸã‚é †æ¬¡å®Ÿè¡Œï¼‰
echo "ä½ã¾ã„ã‚µãƒ¼ãƒ•ã‚£ãƒ³ enrichment (ä¸­å¤) å®Ÿè¡Œä¸­..." >&2
_t=$(date +%s)
python3 sumai_surfin_enricher.py --input "${OUTPUT_DIR}/latest.json" --output "${OUTPUT_DIR}/latest.json" --property-type chuko $BROWSER_FLAG || echo "ä½ã¾ã„ã‚µãƒ¼ãƒ•ã‚£ãƒ³ enrichment (ä¸­å¤) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
record_timing "$TIMING_2A" "sumai_surfin_chuko" "$_t"

if [ "$HAS_SHINCHIKU" = true ]; then
    echo "ä½ã¾ã„ã‚µãƒ¼ãƒ•ã‚£ãƒ³ enrichment (æ–°ç¯‰) å®Ÿè¡Œä¸­..." >&2
    _t=$(date +%s)
    python3 sumai_surfin_enricher.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" --property-type shinchiku $BROWSER_FLAG || echo "ä½ã¾ã„ã‚µãƒ¼ãƒ•ã‚£ãƒ³ enrichment (æ–°ç¯‰) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_2A" "sumai_surfin_shinchiku" "$_t"
fi

# 2a-4. ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆå…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ geocode_cache.json ç­‰ã®ãŸã‚é †æ¬¡å®Ÿè¡Œï¼‰
#       ss_address ç¢ºå®šå¾Œã«å®Ÿè¡Œã™ã‚‹ãŸã‚ã€build_map_viewer ã®ç²¾åº¦ãŒå‘ä¸Š
echo "ç‰©ä»¶ãƒžãƒƒãƒ—ã‚’ç”Ÿæˆä¸­ï¼ˆss_address æ´»ç”¨ã€ä¸­å¤+æ–°ç¯‰ï¼‰..." >&2
_t=$(date +%s)
SHINCHIKU_FLAG=""
if [ "$HAS_SHINCHIKU" = true ]; then
    SHINCHIKU_FLAG="--shinchiku ${OUTPUT_DIR}/latest_shinchiku.json"
fi
python3 scripts/build_map_viewer.py "${OUTPUT_DIR}/latest.json" $SHINCHIKU_FLAG || echo "åœ°å›³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆç¶šè¡Œï¼‰" >&2
record_timing "$TIMING_2A" "build_map_viewer" "$_t"

echo "ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åŸ‹ã‚è¾¼ã¿ä¸­..." >&2
_t=$(date +%s)
python3 scripts/embed_geocode.py "${OUTPUT_DIR}/latest.json" || echo "embed_geocode (ä¸­å¤) ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆç¶šè¡Œï¼‰" >&2
if [ "$HAS_SHINCHIKU" = true ]; then
    python3 scripts/embed_geocode.py "${OUTPUT_DIR}/latest_shinchiku.json" || echo "embed_geocode (æ–°ç¯‰) ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆç¶šè¡Œï¼‰" >&2
fi
record_timing "$TIMING_2A" "embed_geocode" "$_t"

echo "ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¤œè¨¼ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­..." >&2
_t=$(date +%s)
python3 scripts/geocode.py || true
record_timing "$TIMING_2A" "geocode_cache_cleanup" "$_t"

echo "åº§æ¨™ã®ç›¸äº’æ¤œè¨¼ + ä¿®æ­£è©¦è¡Œä¸­..." >&2
_t=$(date +%s)
python3 scripts/geocode_cross_validator.py "${OUTPUT_DIR}/latest.json" --fix || echo "âš  åº§æ¨™ã®ç›¸äº’æ¤œè¨¼ï¼ˆä¸­å¤ï¼‰ã§å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ" >&2
if [ "$HAS_SHINCHIKU" = true ]; then
    python3 scripts/geocode_cross_validator.py "${OUTPUT_DIR}/latest_shinchiku.json" --fix || echo "âš  åº§æ¨™ã®ç›¸äº’æ¤œè¨¼ï¼ˆæ–°ç¯‰ï¼‰ã§å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ" >&2
fi
record_timing "$TIMING_2A" "geocode_cross_validator" "$_t"

record_timing "$TIMING_DIR/main.tsv" "phase2a_total" "$_t_phase2a"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 2b: èª­ã¿å–ã‚Šå°‚ç”¨ enricherï¼ˆ3ãƒˆãƒ©ãƒƒã‚¯ä¸¦åˆ—å®Ÿè¡Œï¼‰
#   - å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¸ã®æ›¸ãè¾¼ã¿ãªã—ï¼ˆgeocode_cache ç­‰ã¯èª­ã¿å–ã‚Šã®ã¿ï¼‰
#   - Track A: ä¸­å¤ï¼ˆlatest.jsonï¼‰
#   - Track B: æ–°ç¯‰ï¼ˆlatest_shinchiku.jsonï¼‰
#   - Track C: æˆç´„å®Ÿç¸¾ãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo "" >&2
echo "--- Phase 2b: èª­ã¿å–ã‚Šå°‚ç”¨ enricherï¼ˆ3ãƒˆãƒ©ãƒƒã‚¯ä¸¦åˆ—å®Ÿè¡Œï¼‰ ---" >&2

TRACK_A_LOG="${OUTPUT_DIR}/.track_a.log"
TRACK_B_LOG="${OUTPUT_DIR}/.track_b.log"
TRACK_C_LOG="${OUTPUT_DIR}/.track_c.log"
> "$TRACK_A_LOG"
> "$TRACK_B_LOG"
> "$TRACK_C_LOG"

_t_phase2b=$(date +%s)

# â”€â”€â”€ Track A: ä¸­å¤ï¼ˆå…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿å–ã‚Šã®ã¿ã® enricherï¼‰ â”€â”€â”€
(
    set +e
    TIMING_FILE="$TIMING_DIR/track_a.tsv"

    echo "=== Track A: ä¸­å¤ enrichment é–‹å§‹ ===" >&2

    echo "ãƒã‚¶ãƒ¼ãƒ‰ enrichment (ä¸­å¤) å®Ÿè¡Œä¸­..." >&2
    _t=$(date +%s)
    python3 hazard_enricher.py --input "${OUTPUT_DIR}/latest.json" --output "${OUTPUT_DIR}/latest.json" || echo "ãƒã‚¶ãƒ¼ãƒ‰ enrichment (ä¸­å¤) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_FILE" "hazard_chuko" "$_t"

    echo "é–“å–ã‚Šå›³ç”»åƒ enrichment (ä¸­å¤) å®Ÿè¡Œä¸­..." >&2
    _t=$(date +%s)
    python3 floor_plan_enricher.py --input "${OUTPUT_DIR}/latest.json" --output "${OUTPUT_DIR}/latest.json" || echo "é–“å–ã‚Šå›³ç”»åƒ enrichment (ä¸­å¤) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_FILE" "floor_plan_chuko" "$_t"

    echo "é€šå‹¤æ™‚é–“ enrichment (ä¸­å¤) å®Ÿè¡Œä¸­..." >&2
    _t=$(date +%s)
    python3 commute_enricher.py --input "${OUTPUT_DIR}/latest.json" --output "${OUTPUT_DIR}/latest.json" || echo "é€šå‹¤æ™‚é–“ enrichment (ä¸­å¤) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_FILE" "commute_chuko" "$_t"

    if [ -f "data/reinfolib_prices.json" ]; then
        echo "ä¸å‹•ç”£æƒ…å ±ãƒ©ã‚¤ãƒ–ãƒ©ãƒª enrichment (ä¸­å¤) å®Ÿè¡Œä¸­..." >&2
        _t=$(date +%s)
        python3 reinfolib_enricher.py --input "${OUTPUT_DIR}/latest.json" --output "${OUTPUT_DIR}/latest.json" || echo "ä¸å‹•ç”£æƒ…å ±ãƒ©ã‚¤ãƒ–ãƒ©ãƒª enrichment (ä¸­å¤) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
        record_timing "$TIMING_FILE" "reinfolib_chuko" "$_t"
    fi

    if [ -f "data/estat_population.json" ]; then
        echo "e-Stat äººå£å‹•æ…‹ enrichment (ä¸­å¤) å®Ÿè¡Œä¸­..." >&2
        _t=$(date +%s)
        python3 estat_enricher.py --input "${OUTPUT_DIR}/latest.json" --output "${OUTPUT_DIR}/latest.json" || echo "e-Stat äººå£å‹•æ…‹ enrichment (ä¸­å¤) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
        record_timing "$TIMING_FILE" "estat_chuko" "$_t"
    fi

    echo "=== Track A: ä¸­å¤ enrichment å®Œäº† ===" >&2
) 2>"$TRACK_A_LOG" &
TRACK_A_PID=$!
register_bg_pid $TRACK_A_PID

# â”€â”€â”€ Track B: æ–°ç¯‰ï¼ˆå…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿å–ã‚Šã®ã¿ã® enricherï¼‰ â”€â”€â”€
TRACK_B_PID=""
if [ "$HAS_SHINCHIKU" = true ]; then
(
    set +e
    TIMING_FILE="$TIMING_DIR/track_b.tsv"

    echo "=== Track B: æ–°ç¯‰ enrichment é–‹å§‹ ===" >&2

    echo "ãƒã‚¶ãƒ¼ãƒ‰ enrichment (æ–°ç¯‰) å®Ÿè¡Œä¸­..." >&2
    _t=$(date +%s)
    python3 hazard_enricher.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" || echo "ãƒã‚¶ãƒ¼ãƒ‰ enrichment (æ–°ç¯‰) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_FILE" "hazard_shinchiku" "$_t"

    echo "é–“å–ã‚Šå›³ç”»åƒ enrichment (æ–°ç¯‰) å®Ÿè¡Œä¸­..." >&2
    _t=$(date +%s)
    python3 floor_plan_enricher.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" || echo "é–“å–ã‚Šå›³ç”»åƒ enrichment (æ–°ç¯‰) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_FILE" "floor_plan_shinchiku" "$_t"

    echo "é€šå‹¤æ™‚é–“ enrichment (æ–°ç¯‰) å®Ÿè¡Œä¸­..." >&2
    _t=$(date +%s)
    python3 commute_enricher.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" || echo "é€šå‹¤æ™‚é–“ enrichment (æ–°ç¯‰) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_FILE" "commute_shinchiku" "$_t"

    if [ -f "data/reinfolib_prices.json" ]; then
        echo "ä¸å‹•ç”£æƒ…å ±ãƒ©ã‚¤ãƒ–ãƒ©ãƒª enrichment (æ–°ç¯‰) å®Ÿè¡Œä¸­..." >&2
        _t=$(date +%s)
        python3 reinfolib_enricher.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" || echo "ä¸å‹•ç”£æƒ…å ±ãƒ©ã‚¤ãƒ–ãƒ©ãƒª enrichment (æ–°ç¯‰) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
        record_timing "$TIMING_FILE" "reinfolib_shinchiku" "$_t"
    fi

    if [ -f "data/estat_population.json" ]; then
        echo "e-Stat äººå£å‹•æ…‹ enrichment (æ–°ç¯‰) å®Ÿè¡Œä¸­..." >&2
        _t=$(date +%s)
        python3 estat_enricher.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" || echo "e-Stat äººå£å‹•æ…‹ enrichment (æ–°ç¯‰) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
        record_timing "$TIMING_FILE" "estat_shinchiku" "$_t"
    fi

    echo "=== Track B: æ–°ç¯‰ enrichment å®Œäº† ===" >&2
) 2>"$TRACK_B_LOG" &
TRACK_B_PID=$!
register_bg_pid $TRACK_B_PID
else
    echo "æ–°ç¯‰ãƒ‡ãƒ¼ã‚¿ãªã—: Track B ã‚¹ã‚­ãƒƒãƒ—" >&2
fi

# â”€â”€â”€ Track C: æˆç´„å®Ÿç¸¾ãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰ â”€â”€â”€
TRACK_C_PID=""
if [ -n "${REINFOLIB_API_KEY:-}" ]; then
(
    set +e
    TIMING_FILE="$TIMING_DIR/track_c.tsv"

    echo "=== Track C: æˆç´„å®Ÿç¸¾ãƒ•ã‚£ãƒ¼ãƒ‰æ§‹ç¯‰é–‹å§‹ ===" >&2

    _t=$(date +%s)
    python3 build_transaction_feed.py --quarters 20 --output "${OUTPUT_DIR}/transactions.json" || echo "æˆç´„å®Ÿç¸¾ãƒ•ã‚£ãƒ¼ãƒ‰æ§‹ç¯‰å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_FILE" "build_transaction_feed" "$_t"

    echo "=== Track C: æˆç´„å®Ÿç¸¾ãƒ•ã‚£ãƒ¼ãƒ‰æ§‹ç¯‰å®Œäº† ===" >&2
) 2>"$TRACK_C_LOG" &
TRACK_C_PID=$!
register_bg_pid $TRACK_C_PID
else
    echo "æˆç´„å®Ÿç¸¾ãƒ•ã‚£ãƒ¼ãƒ‰: REINFOLIB_API_KEY æœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—" >&2
fi

# â”€â”€â”€ å…¨ãƒˆãƒ©ãƒƒã‚¯å®Œäº†å¾…æ©Ÿ â”€â”€â”€
echo "å…¨ãƒˆãƒ©ãƒƒã‚¯å®Œäº†ã‚’å¾…æ©Ÿä¸­..." >&2
TRACK_A_EXIT=0
TRACK_B_EXIT=0
TRACK_C_EXIT=0

wait $TRACK_A_PID || TRACK_A_EXIT=$?
[ -n "$TRACK_B_PID" ] && { wait $TRACK_B_PID || TRACK_B_EXIT=$?; }
[ -n "$TRACK_C_PID" ] && { wait $TRACK_C_PID || TRACK_C_EXIT=$?; }

BG_PIDS=""
record_timing "$TIMING_DIR/main.tsv" "phase2b_parallel_total" "$_t_phase2b"

# ãƒˆãƒ©ãƒƒã‚¯åˆ¥ãƒ­ã‚°ã‚’ãƒ¡ã‚¤ãƒ³ã® stderr ã«å‡ºåŠ›ï¼ˆtee çµŒç”±ã§ LOG_FILE ã«ã‚‚åæ˜ ï¼‰
echo "" >&2
echo "--- Track A ãƒ­ã‚° ---" >&2
cat "$TRACK_A_LOG" >&2
if [ -s "$TRACK_B_LOG" ]; then
    echo "" >&2
    echo "--- Track B ãƒ­ã‚° ---" >&2
    cat "$TRACK_B_LOG" >&2
fi
if [ -s "$TRACK_C_LOG" ]; then
    echo "" >&2
    echo "--- Track C ãƒ­ã‚° ---" >&2
    cat "$TRACK_C_LOG" >&2
fi

echo "" >&2
echo "--- ãƒˆãƒ©ãƒƒã‚¯å®Œäº†çŠ¶æ³ ---" >&2
echo "Track A (ä¸­å¤): exit=$TRACK_A_EXIT" >&2
[ -n "$TRACK_B_PID" ] && echo "Track B (æ–°ç¯‰): exit=$TRACK_B_EXIT" >&2
[ -n "$TRACK_C_PID" ] && echo "Track C (æˆç´„å®Ÿç¸¾): exit=$TRACK_C_EXIT" >&2

rm -f "$TRACK_A_LOG" "$TRACK_B_LOG" "$TRACK_C_LOG"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 2c: å…±æœ‰ãƒžãƒ‹ãƒ•ã‚§ã‚¹ãƒˆæ›¸ãè¾¼ã¿ï¼ˆupload_floor_plans ã‚’é †æ¬¡å®Ÿè¡Œï¼‰
#   - floor_plan_storage_manifest.json ã‚’å®‰å…¨ã«èª­ã¿æ›¸ãã™ã‚‹ãŸã‚é †æ¬¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if [ -n "${FIREBASE_SERVICE_ACCOUNT:-}" ]; then
    echo "" >&2
    echo "--- Phase 2c: Firebase Storage ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆé †æ¬¡å®Ÿè¡Œï¼‰ ---" >&2

    echo "é–“å–ã‚Šå›³ã‚’ Firebase Storage ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ï¼ˆä¸­å¤ï¼‰..." >&2
    _t=$(date +%s)
    python3 upload_floor_plans.py --input "${OUTPUT_DIR}/latest.json" --output "${OUTPUT_DIR}/latest.json" || echo "é–“å–ã‚Šå›³ Storage ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ä¸­å¤) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
    record_timing "$TIMING_DIR/phase2c.tsv" "upload_floor_plans_chuko" "$_t"

    if [ "$HAS_SHINCHIKU" = true ]; then
        echo "é–“å–ã‚Šå›³ã‚’ Firebase Storage ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ï¼ˆæ–°ç¯‰ï¼‰..." >&2
        _t=$(date +%s)
        python3 upload_floor_plans.py --input "${OUTPUT_DIR}/latest_shinchiku.json" --output "${OUTPUT_DIR}/latest_shinchiku.json" || echo "é–“å–ã‚Šå›³ Storage ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (æ–°ç¯‰) å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
        record_timing "$TIMING_DIR/phase2c.tsv" "upload_floor_plans_shinchiku" "$_t"
    fi
else
    echo "é–“å–ã‚Šå›³ Storage ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: FIREBASE_SERVICE_ACCOUNT æœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—" >&2
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 3: åˆæµï¼ˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ â†’ ãƒ¬ãƒãƒ¼ãƒˆ â†’ é€šçŸ¥ â†’ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo "" >&2
echo "--- Phase 3: åˆæµ ---" >&2

# â”€â”€â”€ JSON ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ â”€â”€â”€
if ! python3 -c "import json; json.load(open('${OUTPUT_DIR}/latest.json'))" 2>/dev/null; then
    echo "âš  latest.json ãŒç ´æã—ã¦ã„ã‚‹ãŸã‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒã—ã¾ã™" >&2
    cp "${OUTPUT_DIR}/latest.json.backup" "${OUTPUT_DIR}/latest.json"
fi
if [ -s "${OUTPUT_DIR}/latest_shinchiku.json" ] && ! python3 -c "import json; json.load(open('${OUTPUT_DIR}/latest_shinchiku.json'))" 2>/dev/null; then
    echo "âš  latest_shinchiku.json ãŒç ´æã—ã¦ã„ã‚‹ãŸã‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒã—ã¾ã™" >&2
    cp "${OUTPUT_DIR}/latest_shinchiku.json.backup" "${OUTPUT_DIR}/latest_shinchiku.json" 2>/dev/null || true
fi
rm -f "${OUTPUT_DIR}/latest.json.backup" "${OUTPUT_DIR}/latest_shinchiku.json.backup"

# â”€â”€â”€ ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ â”€â”€â”€
echo "ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ä¸­..." >&2
python3 scripts/validate_data.py "${OUTPUT_DIR}/latest.json" \
    --previous "${OUTPUT_DIR}/previous.json" --label "ä¸­å¤" \
    || echo "âš  ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ã§å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ" >&2
if [ "$HAS_SHINCHIKU" = true ] && [ -s "${OUTPUT_DIR}/latest_shinchiku.json" ]; then
    python3 scripts/validate_data.py "${OUTPUT_DIR}/latest_shinchiku.json" \
        --previous "${OUTPUT_DIR}/previous_shinchiku.json" --label "æ–°ç¯‰" \
        || echo "âš  ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ï¼ˆæ–°ç¯‰ï¼‰ã§å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ" >&2
fi

# â”€â”€â”€ æŠ•è³‡ã‚¹ã‚³ã‚¢ãƒ»ä¾›çµ¦ãƒˆãƒ¬ãƒ³ãƒ‰æ³¨å…¥ï¼ˆenrichment å®Œäº†å¾Œï¼‰ â”€â”€â”€
echo "æŠ•è³‡ã‚¹ã‚³ã‚¢æ³¨å…¥ä¸­..." >&2
_t=$(date +%s)
python3 investment_enricher.py "${OUTPUT_DIR}/latest.json" \
    --transactions "${OUTPUT_DIR}/transactions.json" \
    || echo "æŠ•è³‡ã‚¹ã‚³ã‚¢æ³¨å…¥ï¼ˆä¸­å¤ï¼‰å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
if [ -s "${OUTPUT_DIR}/latest_shinchiku.json" ]; then
    python3 investment_enricher.py "${OUTPUT_DIR}/latest_shinchiku.json" \
        --transactions "${OUTPUT_DIR}/transactions.json" \
        || echo "æŠ•è³‡ã‚¹ã‚³ã‚¢æ³¨å…¥ï¼ˆæ–°ç¯‰ï¼‰å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
fi
record_timing "$TIMING_DIR/main.tsv" "investment_scoring" "$_t"

echo "ä¾›çµ¦ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆä¸­..." >&2
_t=$(date +%s)
SHINCHIKU_TREND_ARGS=""
if [ -s "${OUTPUT_DIR}/latest_shinchiku.json" ]; then
    SHINCHIKU_TREND_ARGS="--current-shinchiku ${OUTPUT_DIR}/latest_shinchiku.json"
    if [ -f "${OUTPUT_DIR}/previous_shinchiku.json" ]; then
        SHINCHIKU_TREND_ARGS="${SHINCHIKU_TREND_ARGS} --previous-shinchiku ${OUTPUT_DIR}/previous_shinchiku.json"
    fi
fi
python3 build_supply_trends.py \
    --current "${OUTPUT_DIR}/latest.json" \
    --previous "${OUTPUT_DIR}/previous.json" \
    $SHINCHIKU_TREND_ARGS \
    --output "${OUTPUT_DIR}/supply_trends.json" \
    || echo "ä¾›çµ¦ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆå¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
record_timing "$TIMING_DIR/main.tsv" "supply_trends" "$_t"

# â”€â”€â”€ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ â”€â”€â”€
echo "ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ï¼ˆenrichment å…¨åæ˜ ï¼‰..." >&2
_t=$(date +%s)
if [ -f "${OUTPUT_DIR}/previous.json" ]; then
    python3 generate_report.py "${OUTPUT_DIR}/latest.json" --compare "${OUTPUT_DIR}/previous.json" -o "$REPORT" $REPORT_URL_ARG $MAP_URL_ARG
else
    python3 generate_report.py "${OUTPUT_DIR}/latest.json" -o "$REPORT" $REPORT_URL_ARG $MAP_URL_ARG
fi
cp "$REPORT" "${OUTPUT_DIR}/report_${DATE}.md"
record_timing "$TIMING_DIR/main.tsv" "report_generation" "$_t"

# â”€â”€â”€ ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ â”€â”€â”€
if [ -n "${FIREBASE_SERVICE_ACCOUNT:-}" ]; then
    echo "ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥é€ä¿¡ä¸­..." >&2
    NEW_CHUKO=$(python3 -c "
import json
print(sum(1 for r in json.load(open('${OUTPUT_DIR}/latest.json')) if r.get('is_new')))
" 2>/dev/null || echo "0")
    NEW_SHINCHIKU=0
    if [ -f "${OUTPUT_DIR}/latest_shinchiku.json" ]; then
        NEW_SHINCHIKU=$(python3 -c "
import json
print(sum(1 for r in json.load(open('${OUTPUT_DIR}/latest_shinchiku.json')) if r.get('is_new')))
" 2>/dev/null || echo "0")
    fi
    python3 scripts/send_push.py --new-count "$NEW_CHUKO" --shinchiku-count "$NEW_SHINCHIKU" || echo "ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥é€ä¿¡å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2
else
    echo "ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥: FIREBASE_SERVICE_ACCOUNT æœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—" >&2
fi

# â”€â”€â”€ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— â”€â”€â”€
rm -f "$CURRENT" "$CURRENT_SHINCHIKU"
for f in "${OUTPUT_DIR}"/current_*.json; do
    [ -f "$f" ] || continue
    rm -f "$f" 2>/dev/null || true
done

OLD_REPORT_DIR="${REPORT_DIR}/old"
mkdir -p "$OLD_REPORT_DIR"
touch "${OLD_REPORT_DIR}/.gitkeep"
for f in "${OUTPUT_DIR}"/report_*.md; do
    [ -f "$f" ] || continue
    [ "$(basename "$f")" = "report_${DATE}.md" ] && continue
    mv "$f" "${OLD_REPORT_DIR}/" 2>/dev/null || true
done
for f in "${REPORT_DIR}"/report_*.md; do
    [ -f "$f" ] || continue
    mv "$f" "${OLD_REPORT_DIR}/" 2>/dev/null || true
done

echo "=== å®Œäº† ===" >&2
echo "ãƒ¬ãƒãƒ¼ãƒˆ: $REPORT" >&2
echo "æœ€æ–°ï¼ˆä¸­å¤ï¼‰: ${OUTPUT_DIR}/latest.json" >&2
echo "æœ€æ–°ï¼ˆæ–°ç¯‰ï¼‰: ${OUTPUT_DIR}/latest_shinchiku.json" >&2
echo "æˆç´„å®Ÿç¸¾: ${OUTPUT_DIR}/transactions.json" >&2

# â”€â”€â”€ æ‰€è¦æ™‚é–“ã‚µãƒžãƒªãƒ¼ â”€â”€â”€
print_timing_summary

# ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
rm -rf "$TIMING_DIR"

# â”€â”€â”€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— â”€â”€â”€
echo "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­..." >&2
python3 scripts/cache_manager.py --stats --cleanup || echo "âš  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2

# â”€â”€â”€ ãƒ­ã‚°ã‚’ Firestore ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â”€â”€â”€
echo "ãƒ­ã‚°ã‚’ Firestore ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..." >&2
python3 upload_scraping_log.py "$LOG_FILE" --status success 2>&1 || echo "ãƒ­ã‚°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆç¶šè¡Œï¼‰" >&2

# â”€â”€â”€ Gitæ“ä½œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³: --no-git ã§ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½ï¼‰ â”€â”€â”€
if [ "$1" != "--no-git" ]; then
    REPO_ROOT="$SCRIPT_DIR"
    while [ ! -d "$REPO_ROOT/.git" ] && [ "$REPO_ROOT" != "/" ]; do
        REPO_ROOT=$(dirname "$REPO_ROOT")
    done
    
    if [ -d "$REPO_ROOT/.git" ]; then
        echo "=== Gitæ“ä½œé–‹å§‹ ===" >&2
        cd "$REPO_ROOT"
        REPORT_FILE="$SCRIPT_DIR/results/report/report.md"
        
        if git diff --quiet && git diff --cached --quiet && [ -z "$(git ls-files -o --exclude-standard scraping-tool/results/)" ]; then
            echo "å¤‰æ›´ãªã—ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰" >&2
        else
            if [ -f "$REPORT_FILE" ]; then
                SUMMARY=$(grep -A 3 "## ðŸ“Š å¤‰æ›´ã‚µãƒžãƒªãƒ¼" "$REPORT_FILE" 2>/dev/null | grep -E "ðŸ†•|ðŸ”„|âŒ" | head -3 | sed 's/^[[:space:]]*- //' | tr '\n' ' ' || echo "")
            fi
            
            COMMIT_MSG="Update listings: ${DATE}"
            if [ -n "$SUMMARY" ]; then
                COMMIT_MSG="${COMMIT_MSG}

${SUMMARY}"
            fi
            COMMIT_MSG="${COMMIT_MSG}

å–å¾—ä»¶æ•°: ${COUNT}ä»¶
ãƒ¬ãƒãƒ¼ãƒˆ: scraping-tool/${REPORT_DIR}/report.md"
            
            git add scraping-tool/results/ scraping-tool/data/floor_plan_storage_manifest.json scraping-tool/data/geocode_cache.json 2>/dev/null || true
            if git diff --cached --quiet; then
                echo "ã‚³ãƒŸãƒƒãƒˆã™ã‚‹å¤‰æ›´ãŒã‚ã‚Šã¾ã›ã‚“" >&2
            else
                git commit -m "$COMMIT_MSG" || echo "ã‚³ãƒŸãƒƒãƒˆå¤±æ•—ï¼ˆå¤‰æ›´ãŒãªã„å¯èƒ½æ€§ï¼‰" >&2
                
                if git remote | grep -q .; then
                    echo "ãƒªãƒ¢ãƒ¼ãƒˆã«ãƒ—ãƒƒã‚·ãƒ¥ä¸­..." >&2
                    git push || echo "ãƒ—ãƒƒã‚·ãƒ¥å¤±æ•—ï¼ˆæ‰‹å‹•ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼‰" >&2
                else
                    echo "ãƒªãƒ¢ãƒ¼ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰" >&2
                fi
            fi
        fi
    else
        echo "Gitãƒªãƒã‚¸ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰" >&2
    fi
fi
