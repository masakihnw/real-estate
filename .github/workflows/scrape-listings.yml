name: Scrape Listings

# WF1: スクレイピング専用ワークフロー
# 中古+新築を並列取得し、artifact 経由で WF2 (Enrich & Report) にデータを渡す。
# 20-40分で完了するため、2時間スケジュールでキャンセルされない。

on:
  schedule:
    # 2時間ごとに実行（1日12回）
    # 22:00 UTC (7:00 JST) の回で Slack 通知を送信
    - cron: '0 */2 * * *'
  workflow_dispatch:
    inputs:
      send_slack:
        description: 'Slack通知を送信する（デフォルト: true）'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

concurrency:
  group: scrape-listings
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: scraping-tool/requirements.txt

      - name: Install dependencies
        working-directory: scraping-tool
        run: pip install -r requirements.txt

      - name: Cache Playwright browsers
        id: playwright-cache
        uses: actions/cache@v5
        with:
          path: ~/.cache/ms-playwright
          key: playwright-chromium-${{ runner.os }}

      - name: Install Playwright browser
        working-directory: scraping-tool
        run: |
          python3 -c "import playwright" 2>/dev/null && playwright install chromium --with-deps || echo "playwright インストールスキップ"

      - name: Run scraping
        id: scrape
        working-directory: scraping-tool
        run: |
          chmod +x scripts/run_scrape.sh
          ./scripts/run_scrape.sh

      - name: Read metadata
        id: metadata
        working-directory: scraping-tool
        run: |
          if [ -f results/metadata.json ]; then
            HAS_CHANGES=$(python3 -c "import json; print(str(json.load(open('results/metadata.json'))['has_changes']).lower())")
            IS_SLACK_TIME=$(python3 -c "import json; print(str(json.load(open('results/metadata.json'))['is_slack_time']).lower())")
            # 手動実行時の Slack 制御
            if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ github.event.inputs.send_slack }}" != "false" ]; then
              IS_SLACK_TIME=true
            fi
            echo "has_changes=${HAS_CHANGES}" >> $GITHUB_OUTPUT
            echo "is_slack_time=${IS_SLACK_TIME}" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "is_slack_time=false" >> $GITHUB_OUTPUT
          fi

      # スクレイピング結果を artifact としてアップロード
      - name: Upload scrape results
        if: steps.metadata.outputs.has_changes == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results
          path: |
            scraping-tool/results/latest_raw.json
            scraping-tool/results/latest_shinchiku_raw.json
          retention-days: 1
          if-no-files-found: error

      # 前回データ (レポート差分用)
      - name: Upload previous data
        if: steps.metadata.outputs.has_changes == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: scrape-previous
          path: |
            scraping-tool/results/latest.json
            scraping-tool/results/latest_shinchiku.json
          retention-days: 1
          if-no-files-found: warn

      # メタデータ
      - name: Upload metadata
        uses: actions/upload-artifact@v4
        with:
          name: scrape-metadata
          path: scraping-tool/results/metadata.json
          retention-days: 1

      # キャッシュファイル群 (enrichment で必要)
      - name: Upload cache files
        if: steps.metadata.outputs.has_changes == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: scrape-caches
          path: |
            scraping-tool/data/geocode_cache.json
            scraping-tool/data/sumai_surfin_cache.json
            scraping-tool/data/building_units.json
            scraping-tool/data/floor_plan_storage_manifest.json
            scraping-tool/data/reinfolib_prices.json
            scraping-tool/data/reinfolib_trends.json
            scraping-tool/data/reinfolib_raw_transactions.json
            scraping-tool/data/reinfolib_land_prices.json
            scraping-tool/data/station_price_history.json
            scraping-tool/data/estat_population.json
            scraping-tool/data/station_cache.json
            scraping-tool/data/reverse_geocode_cache.json
            scraping-tool/data/shutoken_city_codes.json
          retention-days: 1
          if-no-files-found: warn
